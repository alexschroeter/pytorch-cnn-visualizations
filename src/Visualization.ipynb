{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cace3cce9554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# this mounts your Google Drive to the Colab VM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Create a clone of the repository in your Google Drive with the and link the folder below.\n",
    "\n",
    "# this mounts your Google Drive to the Colab VM.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# enter the foldername in your Drive where you have saved the unzipped\n",
    "# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
    "FOLDERNAME = \"cv2020project/python/pytorch-cnn-visualizations/src\"\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# this downloads the CIFAR-10 dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "%cd drive/My\\ Drive/$FOLDERNAME/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aschroeter/cv2020project/python/pytorch-cnn-visualizations/src\n"
     ]
    }
   ],
   "source": [
    "%cd src\n",
    "from cnn_layer_visualization import CNNLayerVisualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/aschroeter/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fe6a059ab3473e9f87c577aa483cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1 Loss: 1.16\n",
      "Iteration: 2 Loss: -2.16\n",
      "Iteration: 3 Loss: -8.99\n",
      "Iteration: 4 Loss: -16.27\n",
      "Iteration: 5 Loss: -23.25\n",
      "Iteration: 6 Loss: -29.73\n",
      "Iteration: 7 Loss: -35.95\n",
      "Iteration: 8 Loss: -41.89\n",
      "Iteration: 9 Loss: -47.57\n",
      "Iteration: 10 Loss: -53.08\n",
      "Iteration: 11 Loss: -58.51\n",
      "Iteration: 12 Loss: -63.84\n",
      "Iteration: 13 Loss: -69.07\n",
      "Iteration: 14 Loss: -74.23\n",
      "Iteration: 15 Loss: -79.33\n",
      "Iteration: 16 Loss: -84.40\n",
      "Iteration: 17 Loss: -89.45\n",
      "Iteration: 18 Loss: -94.45\n",
      "Iteration: 19 Loss: -99.47\n",
      "Iteration: 20 Loss: -104.46\n",
      "Iteration: 21 Loss: -109.45\n",
      "Iteration: 22 Loss: -114.44\n",
      "Iteration: 23 Loss: -119.45\n",
      "Iteration: 24 Loss: -124.48\n",
      "Iteration: 25 Loss: -129.51\n",
      "Iteration: 26 Loss: -134.57\n",
      "Iteration: 27 Loss: -139.64\n",
      "Iteration: 28 Loss: -144.72\n",
      "Iteration: 29 Loss: -149.84\n",
      "Iteration: 30 Loss: -154.99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "\n",
    "cnn_layer = 17\n",
    "filter_pos = 5\n",
    "# Fully connected layer is not needed\n",
    "pretrained_model = models.vgg16(pretrained=True).features\n",
    "layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)\n",
    "\n",
    "# Layer visualization with pytorch hooks\n",
    "layer_vis.visualise_layer_with_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Guided Grad-Cam</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guided_gradcam import guided_grad_cam\n",
    "import numpy as np\n",
    "\n",
    "from misc_functions import (get_example_params,\n",
    "                            convert_to_grayscale,\n",
    "                            save_gradient_images)\n",
    "from gradcam import GradCam\n",
    "from guided_backprop import GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad cam completed\n",
      "Guided backpropagation completed\n",
      "Guided grad cam completed\n"
     ]
    }
   ],
   "source": [
    "# Get params\n",
    "target_example = 0  # Snake\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n",
    "\n",
    "# Grad cam\n",
    "gcv2 = GradCam(pretrained_model, target_layer=11)\n",
    "# Generate cam mask\n",
    "cam = gcv2.generate_cam(prep_img, target_class)\n",
    "print('Grad cam completed')\n",
    "\n",
    "# Guided backprop\n",
    "GBP = GuidedBackprop(pretrained_model)\n",
    "# Get gradients\n",
    "guided_grads = GBP.generate_gradients(prep_img, target_class)\n",
    "print('Guided backpropagation completed')\n",
    "\n",
    "# Guided Grad cam\n",
    "cam_gb = guided_grad_cam(cam, guided_grads)\n",
    "save_gradient_images(cam_gb, file_name_to_export + '_GGrad_Cam')\n",
    "grayscale_cam_gb = convert_to_grayscale(cam_gb)\n",
    "save_gradient_images(grayscale_cam_gb, file_name_to_export + '_GGrad_Cam_gray')\n",
    "print('Guided grad cam completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Guided Backprop</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guided_backprop import GuidedBackprop\n",
    "\n",
    "import torch\n",
    "from torch.nn import ReLU\n",
    "\n",
    "from misc_functions import (get_example_params,\n",
    "                            convert_to_grayscale,\n",
    "                            save_gradient_images,\n",
    "                            get_positive_negative_saliency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided backprop completed\n"
     ]
    }
   ],
   "source": [
    "target_example = 0  # Snake\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n",
    "\n",
    "# Guided backprop\n",
    "GBP = GuidedBackprop(pretrained_model)\n",
    "# Get gradients\n",
    "guided_grads = GBP.generate_gradients(prep_img, target_class)\n",
    "# Save colored gradients\n",
    "save_gradient_images(guided_grads, file_name_to_export + '_Guided_BP_color')\n",
    "# Convert to grayscale\n",
    "grayscale_guided_grads = convert_to_grayscale(guided_grads)\n",
    "# Save grayscale gradients\n",
    "save_gradient_images(grayscale_guided_grads, file_name_to_export + '_Guided_BP_gray')\n",
    "# Positive and negative saliency maps\n",
    "pos_sal, neg_sal = get_positive_negative_saliency(guided_grads)\n",
    "save_gradient_images(pos_sal, file_name_to_export + '_pos_sal')\n",
    "save_gradient_images(neg_sal, file_name_to_export + '_neg_sal')\n",
    "print('Guided backprop completed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Score Cam - Score-weighted Class Activation Heatmap on Image (Score-CAM)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scorecam import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from misc_functions import get_example_params, save_class_activation_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get params\n",
    "target_example = 0  # Snake\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score cam\n",
    "score_cam = ScoreCam(pretrained_model, target_layer=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate cam mask\n",
    "cam = score_cam.generate_cam(prep_img, target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score cam completed\n"
     ]
    }
   ],
   "source": [
    "# Save mask\n",
    "save_class_activation_images(original_image, cam, file_name_to_export)\n",
    "print('Score cam completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Snake](../results/snake_Cam_On_Image.png)\n",
    "![Snake](../results/snake_Cam_Heatmap.png)\n",
    "![Snake](../results/snake_Cam_Grayscale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Grad Cam - Gradient-weighted Class Activation Heatmap on Image (Grad-CAM)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradcam import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from misc_functions import get_example_params, save_class_activation_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad cam completed\n"
     ]
    }
   ],
   "source": [
    "# Get params\n",
    "target_example = 0  # Snake\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n",
    "# Grad cam\n",
    "grad_cam = GradCam(pretrained_model, target_layer=11)\n",
    "# Generate cam mask\n",
    "cam = grad_cam.generate_cam(prep_img, target_class)\n",
    "# Save mask\n",
    "save_class_activation_images(original_image, cam, file_name_to_export)\n",
    "print('Grad cam completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Snake](../results/snake_Cam_On_Image.png)\n",
    "![Snake](../results/snake_Cam_Heatmap.png)\n",
    "![Snake](../results/snake_Cam_Grayscale.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradcam import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from misc_functions import get_example_params, save_class_activation_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad cam completed\n"
     ]
    }
   ],
   "source": [
    "# Get params\n",
    "target_example = 0  # Snake\n",
    "(original_image, prep_img, target_class, file_name_to_export, pretrained_model) =\\\n",
    "    get_example_params(target_example)\n",
    "# Grad cam\n",
    "grad_cam = GradCam(pretrained_model, target_layer=11)\n",
    "# Generate cam mask\n",
    "cam = grad_cam.generate_cam(prep_img, target_class)\n",
    "# Save mask\n",
    "save_class_activation_images(original_image, cam, file_name_to_export)\n",
    "print('Grad cam completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Snake](../results/snake_Cam_On_Image.png)\n",
    "![Snake](../results/snake_Cam_Heatmap.png)\n",
    "![Snake](../results/snake_Cam_Grayscale.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
